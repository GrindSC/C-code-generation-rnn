{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "GUmLMW83oQ5w"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import Input, Dense, TimeDistributed, Activation, RepeatVector, Bidirectional, Dropout, LSTM, GRU, Embedding\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
        "from tensorflow.keras.layers import Bidirectional"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "_4s919VRcxSX"
      },
      "outputs": [],
      "source": [
        "with open('/content/kod.txt', 'r') as file:\n",
        "      data = re.split('\\n',file.read())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x=[]\n",
        "y=[]\n",
        "for i in range(len(data)):\n",
        "  if(i%2==0):\n",
        "    x.append(data[i])\n",
        "  else:\n",
        "    y.append(data[i])"
      ],
      "metadata": {
        "id": "vwD36AN0g-yI"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "G-b6we0kqr6V"
      },
      "outputs": [],
      "source": [
        "class Tokenizer():\n",
        "  def __init__(self):\n",
        "    # Dwa osobne słowniki dla treści zadania o odpowiadającemu im kodu\n",
        "    self.dictionaryX={'':0}\n",
        "    self.dictionaryY={'':0}\n",
        "\n",
        "  def tokenize(self, sentence:str, isInput:bool=True)->list:\n",
        "    # Dobór słownika z zależności czy przetwarzany jest kod lub tekst\n",
        "    tokenized=[]\n",
        "    if(isInput):\n",
        "      tokenDict=self.dictionaryX\n",
        "    else:\n",
        "      tokenDict=self.dictionaryY\n",
        "    # Zamiana słowa na odpowiadający mu token ze słownika\n",
        "    # Jeśli słowo nie istnieje to najpierw dodanie go do słownika a następnie zamiana\n",
        "    idx=max(tokenDict.values())+1\n",
        "    for word in sentence.split(\" \"):\n",
        "      if(word in tokenDict):\n",
        "        tokenized.append(tokenDict[word])\n",
        "      else:\n",
        "        tokenDict[word]=idx\n",
        "        idx+=1\n",
        "        tokenized.append(tokenDict[word])\n",
        "    return tokenized\n",
        "\n",
        "  def detokenize(self, logits:np.array, isOutput:bool=True)->list:\n",
        "    # Odwrócenie słownika w zależności czy przetwarzany jest tekst czy kod\n",
        "    if(isOutput):\n",
        "      tokenDict = {v: k for k, v in self.dictionaryY.items()}\n",
        "    else:\n",
        "      tokenDict = {v: k for k, v in self.dictionaryX.items()}\n",
        "    return [tokenDict[token] for token in logits]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "NDCfump1qwa0"
      },
      "outputs": [],
      "source": [
        "def loss_fn(model, x, y, y_len, max_sequence):\n",
        "    sequence_loss = tf.keras.losses.sparse_categorical_crossentropy(\n",
        "        y_true=y, y_pred=model(x), from_logits=True\n",
        "    )\n",
        "    sequence_loss = tf.reduce_mean(tf.reduce_sum(sequence_loss, axis=1) )\n",
        "    return sequence_loss\n",
        "\n",
        "class Pipeline():\n",
        "  def __init__(self,x:list, y:list):\n",
        "    self.tokenizer=Tokenizer()\n",
        "    # Zamiania danych na tokeny a następnie dodanie paddingu w celu\n",
        "    # ujednolicenia długości tekstu\n",
        "    self.x=tf.keras.preprocessing.sequence.pad_sequences(\n",
        "      [self.tokenizer.tokenize(s, True) for s in x],  padding=\"post\"\n",
        "    )\n",
        "    self.y=tf.keras.preprocessing.sequence.pad_sequences(\n",
        "      [self.tokenizer.tokenize(s, False) for s in y], padding=\"post\"\n",
        "    )\n",
        "    self.model=self.create_model()\n",
        "    self.sequnce_length = (self.y != 0).astype(np.float32)\n",
        "    self.model.compile()\n",
        "    self.model.summary()\n",
        "\n",
        "  def create_model(self)->tf.keras.Model:\n",
        "    input_vocab_size=len(self.tokenizer.dictionaryX) # Ilość unikalnych tokenów w słowniku X\n",
        "    output_vocab_size=len(self.tokenizer.dictionaryY) # Ilość unikalnych tokenów w słowniku Y\n",
        "    embedded_vector_size=1000 # długość wektora po embeddingu\n",
        "    input_length=self.x.shape[1] # maksymalna długość wejścia z paddingiem\n",
        "    output_length=self.y.shape[1] # maksymalna długość wyjścia z paddingiem\n",
        "    batch_size=2\n",
        "    model = Sequential([\n",
        "    Embedding(input_dim=input_vocab_size, output_dim=embedded_vector_size,\n",
        "              mask_zero=False, trainable=False, input_length=input_length,\n",
        "              embeddings_initializer=tf.keras.initializers.random_normal()),\n",
        "    Bidirectional(LSTM(input_length, return_sequences=False)),\n",
        "    RepeatVector(output_length),\n",
        "    LSTM(64, return_sequences=True),\n",
        "    LSTM(128, return_sequences=True),\n",
        "    Dropout(0.2),\n",
        "    TimeDistributed(Dense(512)),\n",
        "    Dropout(0.2),\n",
        "    TimeDistributed(Dense(units=output_vocab_size))\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "  def predict(self,sentence:str):\n",
        "    print(sentence)\n",
        "    sentence=self.tokenizer.tokenize(sentence)\n",
        "    sentence=tf.keras.preprocessing.sequence.pad_sequences(\n",
        "      np.expand_dims(sentence, axis=0), maxlen=self.x.shape[1] , padding=\"post\"\n",
        "    )\n",
        "    print(sentence)\n",
        "    prediction=self.model.predict(sentence)\n",
        "    prediction=list(np.argmax(prediction[0],axis=1))\n",
        "    print(prediction)\n",
        "    return ' '.join(self.tokenizer.detokenize(prediction))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wH2wrDuOvOPx",
        "outputId": "1dd2749f-8011-43ae-d402-705e8c9ba1b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 39, 1000)          97000     \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirectio  (None, 78)               324480    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " repeat_vector_1 (RepeatVect  (None, 60, 78)           0         \n",
            " or)                                                             \n",
            "                                                                 \n",
            " lstm_4 (LSTM)               (None, 60, 64)            36608     \n",
            "                                                                 \n",
            " lstm_5 (LSTM)               (None, 60, 128)           98816     \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 60, 128)           0         \n",
            "                                                                 \n",
            " time_distributed_2 (TimeDis  (None, 60, 512)          66048     \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 60, 512)           0         \n",
            "                                                                 \n",
            " time_distributed_3 (TimeDis  (None, 60, 40)           20520     \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 643,472\n",
            "Trainable params: 546,472\n",
            "Non-trainable params: 97,000\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "pipeline=Pipeline(x,y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "1gbMkxDavDqk"
      },
      "outputs": [],
      "source": [
        "X_mask = (pipeline.x != 0).astype(np.float32)\n",
        "Y_mask = (pipeline.y != 0).astype(np.float32)\n",
        "X_len = np.array([len(sentence.split(\" \")) for sentence in x], dtype=np.float32)\n",
        "Y_len = np.array([len(sentence.split(\" \")) for sentence in y], dtype=np.float32)\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((pipeline.x, pipeline.y, Y_len)).shuffle(buffer_size=4).batch(batch_size=10)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jUIGGpfQteIC",
        "outputId": "50ee7f2d-4648-424b-8fd1-1ee4c3901f59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 100, tr_loss: 84.110\n",
            "Epoch: 200, tr_loss: 46.651\n",
            "Epoch: 300, tr_loss: 38.187\n",
            "Epoch: 400, tr_loss: 2.566\n",
            "Epoch: 500, tr_loss: 43.163\n"
          ]
        }
      ],
      "source": [
        "tr_loss_hist = []\n",
        "for e in range(500):\n",
        "  avg_tr_loss = 0\n",
        "  tr_step = 0\n",
        "  for x_mb, y_mb, x_mb_len in train_ds:\n",
        "      with tf.GradientTape() as tape:\n",
        "          tr_loss = loss_fn(pipeline.model, x_mb, y_mb, x_mb_len, max_sequence=pipeline.y.shape[1])\n",
        "      grads = tape.gradient(tr_loss, pipeline.model.trainable_variables)\n",
        "      optimizer.apply_gradients(grads_and_vars=zip(grads, pipeline.model.trainable_variables))\n",
        "      avg_tr_loss += tr_loss\n",
        "      tr_step += 1\n",
        "  avg_tr_loss /= tr_step\n",
        "  tr_loss_hist.append(avg_tr_loss)\n",
        "  \n",
        "  if (e + 1) % 100 == 0:\n",
        "      print('Epoch: {:3}, tr_loss: {:.3f}'.format(e+1, avg_tr_loss))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I1eFq36LutI4",
        "outputId": "43f7d6f4-6280-4ca5-de16-7f793baaed35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "wykorzystując funkcję printf napisz program wyświetlający na ekranie napis \" Moj pierwszy program \"\n",
            "[[ 1  2  3  4  5  6  3  7  8  9 10  7  4 11 12 13 11 14  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0]]\n",
            "int main ( ) { printf ( \" Moj pierwszy program \" ) ; return 0 ; }                                          \n"
          ]
        }
      ],
      "source": [
        "num=0\n",
        "sentence=pipeline.x[num]\n",
        "y_pred = pipeline.model.predict(np.expand_dims(sentence,axis=0))\n",
        "y_pred = np.argmax(y_pred, axis=-1) \n",
        "print(x[num])\n",
        "print(y_pred)\n",
        "print(' '.join(pipeline.tokenizer.detokenize(list(y_pred[0]))))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "codegen.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}